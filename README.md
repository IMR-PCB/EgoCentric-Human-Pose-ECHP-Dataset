# EgoCentric-Human-Action(ECHA) Dataset
This is the official version of ECHA dataset
## Introduction
To address the challenges in egocentric 3D pose estimation, we propose a real-world egocentric human action dataset, named ECHA, using a head-mounted GoPro camera with a fisheye lens. The training and validation sets of the ECHA dataset consist of **30** video sequences(**fps=30Hz**) recorded in **8** diverse real-world indoor/outdoor scenes with **10** different daily actions performed by **9** subjects in **20** different body textures. The ten daily actions include: squatting, walking, dancing, stretching, waving, boxing, kicking, touching, clamping, knocking.
